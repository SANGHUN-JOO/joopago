# -*- coding: utf-8 -*-
"""pv_mcts.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18ZOUL_rKCfvKADYqLiNYLwCzQX-AQFNZ
"""

#from game import State
from dual_network import DN_INPUT_SHAPE
from math import sqrt
from tensorflow.keras.models import load_model
from pathlib import Path
import numpy as np
import features
from go import Position
import go
import random

PV_EVALUATE_COUNT = 150 # origianl : 1600

def get_legal_actions(legal_moves):
    legal_actions = []
    for i in range(len(legal_moves)):
        if legal_moves[i] == 1:
            legal_actions.append(i)
    return legal_actions


def predict(model, state):
    a, b, c = DN_INPUT_SHAPE
    x = features.extract_features(state, features.AGZ_FEATURES)

    x = x.reshape(1, a, b, c) # 1 9 9 9 or 1 9 9 17 because of board's size(9x9)
    x = x.astype('float64')
    #print(x.shape)
    #print('aaaaa')
    y = model.predict(x, batch_size=1)
    policies = y[0][0][get_legal_actions(state.all_legal_moves())]
    
    #print(policies)
    if sum(policies) != 0:
        policies /= sum(policies)
    
    value = y[1][0][0]
    #print(value)
    return policies, value

def nodes_to_scores(nodes):
    scores = []
    for c in nodes:
        scores.append(c.n)
    return scores

def pv_mcts_scores(model, state, temperature, p_fail_count):

    class Node:
        def __init__(self, state, p):
            self.state = state
            self.p = p
            self.w = 0
            self.n = 0
            self.child_nodes = None
        
        def evaluate(self):
            if self.state.is_game_over():
                result = state.result()
                color = state.to_play
                if color == 1: #black
                    value = result
                else: #white
                    value = -result

                self.w += value
                self.n += 1
                return value
            
            if self.child_nodes == None:
                policies, value = predict(model, self.state)

                self.w += value
                self.n += 1

                self.child_nodes = []
                for action, policy in zip(get_legal_actions(self.state.all_legal_moves()), policies):
                    coord_row = action // go.N
                    coord_column = action % go.N
                    coord = (coord_row, coord_column)
                    if action == (go.N * go.N):
                        coord = None
                    #print("coord : {}".format(coord))
                    self.child_nodes.append(Node(self.state.play_move(coord), policy))
                return value
            else:
                value = -self.next_child_node().evaluate()

                self.w += value
                self.n += 1
                return value      
            
        def next_child_node(self):
        #    for child_node in self.child_nodes:
        #        if child_node.n == 0:
        #            return child_node
            
            C_PUCT = 0.2
            t = sum(nodes_to_scores(self.child_nodes))
            pucb_values = []
            for child_node in self.child_nodes:
                pucb_values.append(((- child_node.w / child_node.n) if child_node.n else 0.0) +
                                  C_PUCT * child_node.p * sqrt(t) / (1 + child_node.n*2))
            return self.child_nodes[np.argmax(pucb_values)]

    root_node = Node(state, 0)
    state_n = len(get_legal_actions(state.all_legal_moves()))
    evaluate_count = min(PV_EVALUATE_COUNT, state_n*3)

    evaluate_count += p_fail_count * 20
    
    for _ in range(evaluate_count):
        root_node.evaluate()
    
    scores = nodes_to_scores(root_node.child_nodes)

    if temperature == 0:
        action = np.argmax(scores)
        scores = np.zeros(len(scores))
        scores[action] = 1
    else:
        scores = boltzman(scores, temperature)
    
    return scores

def pv_mcts_action(model, temperature=0.0):
    def pv_mcts_action(state):
        scores = pv_mcts_scores(model, state, temperature, 0)
        action = np.random.choice(get_legal_actions(state.all_legal_moves()), p=scores)
        if action == (go.N * go.N):
            return None
        coord_row = action // go.N
        coord_column = action % go.N
        pv_mcts_coord = (coord_row, coord_column)
        return pv_mcts_coord
    
    return pv_mcts_action

def boltzman(xs, temperature):
    xs = [x ** (1 / temperature) for x in xs]
    return [x / sum(xs) for x in xs]

if __name__ == '__main__':
    cur_dir = Path(__file__).parent.absolute()
    cur_dir = cur_dir / 'model'
    
    path = sorted(cur_dir.glob('*.h5'))[-1]
    model = load_model(str(path))

    state = Position()
    
    next_action = pv_mcts_action(model, 1.0)

    while True:
        if state.is_game_over():
            print(state.result_string())
            break
        action = next_action(state)

        state = state.play_move(action)

        print(state.__str__(False))
        print()