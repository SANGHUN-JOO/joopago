# -*- coding: utf-8 -*-
"""self_play.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V_dJVD1JOnJTV-4xv3_HLcLCPhKrAGlO
"""

#from game import State
from pv_mcts import pv_mcts_scores
from pv_mcts import get_legal_actions
from pv_mcts import pv_mcts_action
from dual_network import DN_OUTPUT_SIZE
from datetime import datetime
from tensorflow.keras.models import load_model
from tensorflow.keras import backend as K
from pathlib import Path
import numpy as np
import pickle
import os
import go
import features

SP_GAME_COUNT = 50 # original = 25000
SP_TEMPERATURE = 1.0

def first_player_value(ended_state):
    if ended_state.is_lose():
        if ended_state.is_first_player():
            return -1
        else:
            return 1
    return 0

def write_data(history):
    now = datetime.now()
    cur_dir = Path(__file__).parent.absolute()
    cur_dir = cur_dir / 'data'
    os.makedirs(cur_dir, exist_ok=True)
    path = str(cur_dir) + '\\{:04}{:02}{:02}{:02}{:02}{:02}.history'.format(now.year, now.month, now.day, now.hour, now.minute, now.second)

    with open(path, mode='wb') as f:
        pickle.dump(history, f)

def play(model, p_fail_count):
    history = []

    state = go.Position()

    while True:
        if state.is_game_over():
            break
        
        scores = pv_mcts_scores(model, state, SP_TEMPERATURE, p_fail_count)

        policies = [0] * DN_OUTPUT_SIZE
        for action, policy in zip(get_legal_actions(state.all_legal_moves()), scores):
            policies[action] = policy

        x = features.extract_features(state, features.AGZ_FEATURES)

        history.append([x, policies, None])

        pv_mcts_coord = None
        action = np.random.choice(get_legal_actions(state.all_legal_moves()), p=scores)
        if action == (go.N * go.N):
            pv_mcts_coord = None
        else:
            coord_row = action // go.N
            coord_column = action % go.N
            pv_mcts_coord = (coord_row, coord_column)

        state = state.play_move(pv_mcts_coord)

    value = state.result()
    
    for i in range(len(history)):
        history[i][2] = value
        value = -value
    
    return history

def self_play(p_fail_count):
    history = []

    cur_dir = Path(__file__).parent.absolute()

    model = load_model(str(cur_dir) + '\\model\\best.h5')

    for i in range(SP_GAME_COUNT + p_fail_count):
        h = play(model, p_fail_count)
        history.extend(h)

        print('\rSelfPlay {}/{}'.format(i+1, SP_GAME_COUNT), end='')
    print('')

    write_data(history)

    K.clear_session()
    del model

if __name__ == '__main__':
    self_play()